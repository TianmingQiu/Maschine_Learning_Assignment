close all; clear; clc;
load('dataGMM.mat');

%% initialize by kmeans
Data = Data';
[sample_number, dim] = size(Data);
% number of clusters
K = 4;
[idx, mean]=kmeans(Data, K);

%% get initial parameter
pi = zeros(1, K);
sigma = zeros(dim, dim, K);
for k = 1 : K
    class_label = (idx == k);
    pi(k) = sum(class_label) / sample_number;
    sigma(:,:,k) = cov(Data(class_label,:));
end

%% EM iteration
iteration_flag = 1;
pi_est = zeros(1, K);
resp = zeros(sample_number, K);
mean_est = zeros(K, dim);
sigma_est = zeros(dim, dim, K);
log_likelihood = 0;
log_likelihood_est = 0;
while iteration_flag ~= 0
    for k = 1 : K
        % E-Step
        resp(:, k) = response(Data, pi, k, mean, sigma);
        % M-Step
        n(k) = sum(resp);
        mean_est(k, :) = sum(resp .* Data) / n(k);
        for i = 1 : sample_number
            sigma_est(:,:,k) = sigma_est(:,:,k) + (Data(i, :) - ...
                mean_est(k, :))' * (Data(i, :) - mean_est(k, :)) .* resp(i);
        end
        sigma_est(:,:,k) = sigma_est(:,:,k) ./ n(k);
        pi_est(k) = n(k) / sample_number;
    end
    
    % update
    mean = mean_est;
    pi = pi-est;
    sigma = sigma_est; 
    % check for convergence through log-likelihood
    for k = 1 : K
    log_likelihood = pi(k) * gaussian_pdf()
    end
    
    iteration_flag = 0;
end


%% Calculation for responsibility and multivariable Gaussian PDF
function resp = response(x, pi, k, mean, sigma)
numerator = pi(k) * gaussian_pdf(x, sigma(:,:,k), mean(k, :));
denominator = 0;
for j = 1 : 4
    denominator = denominator + pi(j) * gaussian_pdf(x, sigma(:,:,j), mean(j, :));
end
resp = numerator ./ denominator;
end

function pdf = gaussian_pdf(x, sigma, mean)
k = size(x, 1);
pdf = 1 / sqrt((2 * pi) ^ k * det(sigma)) ...
    * exp(-1 / 2 * ((x - mean) * inv(sigma) * (x - mean)'));
pdf = diag(pdf);
end